{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d564b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9504aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    " def clean_price_column_robust(col):\n",
    "    \"\"\"Robust price cleaning for formats like '55.00/kg'\"\"\"\n",
    "    if col.dtype == 'object': \n",
    "        col = col.replace(['-', '', 'NA', 'N/A', 'nan', 'NaN'], np.nan)\n",
    "         \n",
    "        col = col.str.replace('/kg', '', case=False, regex=False)\n",
    "        col = col.str.replace('/Kg', '', case=False, regex=False)\n",
    "        col = col.str.replace('ksh', '', case=False, regex=False)\n",
    "        col = col.str.replace('kes', '', case=False, regex=False)\n",
    "        col = col.str.replace(' ', '', regex=False)  \n",
    "        col = col.str.replace(',', '', regex=False)  \n",
    "        col = pd.to_numeric(col, errors='coerce')\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0c982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_with_proper_cleaning():\n",
    "    \"\"\"Prepare data with robust price cleaning\"\"\"\n",
    "    df = pd.read_csv(\"../data/raw/kamis_data.csv\")\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "    \n",
    "    print(\"BEFORE CLEANING:\")\n",
    "    print(f\"Retail price sample: {df['Retail'].head().tolist()}\")\n",
    "    if 'Wholesale' in df.columns:\n",
    "        print(f\"Wholesale price sample: {df['Wholesale'].head().tolist()}\")\n",
    "     \n",
    "    df['Retail'] = clean_price_column_robust(df['Retail'])\n",
    "    if 'Wholesale' in df.columns:\n",
    "        df['Wholesale'] = clean_price_column_robust(df['Wholesale'])\n",
    "     \n",
    "    if 'Supply Volume' in df.columns:\n",
    "        df['Supply Volume'] = pd.to_numeric(df['Supply Volume'], errors='coerce')\n",
    "    \n",
    "    print(\"\\nAFTER CLEANING:\")\n",
    "    print(f\"Retail price sample: {df['Retail'].head().tolist()}\")\n",
    "    if 'Wholesale' in df.columns:\n",
    "        print(f\"Wholesale price sample: {df['Wholesale'].head().tolist()}\")\n",
    "     \n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=['Retail'])\n",
    "    final_count = len(df)\n",
    "    \n",
    "    print(f\"\\nDATA CLEANING SUMMARY:\")\n",
    "    print(f\"Initial rows: {initial_count:,}\")\n",
    "    print(f\"After removing missing retail prices: {final_count:,}\")\n",
    "    print(f\"Rows removed: {initial_count - final_count:,}\")\n",
    "    print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "    \n",
    "    print(f\"\\nPRICE STATISTICS:\")\n",
    "    print(f\"Retail - Mean: {df['Retail'].mean():.2f}, Std: {df['Retail'].std():.2f}\")\n",
    "    print(f\"Retail - Min: {df['Retail'].min():.2f}, Max: {df['Retail'].max():.2f}\")\n",
    "    \n",
    "    if 'Wholesale' in df.columns:\n",
    "        print(f\"Wholesale - Mean: {df['Wholesale'].mean():.2f}, Std: {df['Wholesale'].std():.2f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330dfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_groupby_transform(df, group_cols, column, operation, window=None):\n",
    "    \"\"\"Safe groupby transform that preserves index and avoids length mismatches\"\"\"\n",
    "    results = []\n",
    "    original_index = df.index\n",
    "    \n",
    "    for name, group in df.groupby(group_cols):\n",
    "        group = group.sort_values('Date')\n",
    "        if window:\n",
    "            result = operation(group[column].shift(1).rolling(window=window, min_periods=1))\n",
    "        else:\n",
    "            result = operation(group[column])\n",
    "        \n",
    "        if hasattr(result, 'values'):\n",
    "            result_series = pd.Series(result.values, index=group.index)\n",
    "        else:\n",
    "            result_series = pd.Series(result, index=group.index)\n",
    "        results.append(result_series)\n",
    "     \n",
    "    combined = pd.concat(results)\n",
    "    return combined.reindex(original_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106bf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future_safe_features(df, target_col='Retail'):\n",
    "    \"\"\"Create features for future prediction with properly cleaned prices\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort by date to ensure proper time series\n",
    "    df = df.sort_values(['Commodity', 'Market', 'County', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    # BASIC TEMPORAL FEATURES \n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['week_of_year'] = df['Date'].dt.isocalendar().week\n",
    "    df['day_of_year'] = df['Date'].dt.dayofyear\n",
    "    df['quarter'] = df['Date'].dt.quarter\n",
    "    df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "    \n",
    "    # KENYAN SEASONAL FEATURES\n",
    "    df['is_long_rains'] = (df['month'] >= 3) & (df['month'] <= 5)\n",
    "    df['is_short_rains'] = (df['month'] >= 10) & (df['month'] <= 12)\n",
    "    df['is_planting_season'] = df['month'].isin([3, 4, 10])\n",
    "    df['is_harvest_season'] = df['month'].isin([7, 8, 1, 2])\n",
    "    \n",
    "    # LAG FEATURES - ONLY PAST RETAIL PRICES\n",
    "    group_cols = ['Commodity', 'Market', 'County']\n",
    "    \n",
    "    print(\"Creating lag features...\") \n",
    "    lags = [1, 2, 3, 4]   \n",
    "    for lag in lags:\n",
    "        df[f'retail_lag_{lag}'] = df.groupby(group_cols)[target_col].shift(lag)\n",
    " \n",
    "    if 'Wholesale' in df.columns:\n",
    "        wholesale_lags = [1, 2, 4]\n",
    "        for lag in wholesale_lags:\n",
    "            df[f'wholesale_lag_{lag}'] = df.groupby(group_cols)['Wholesale'].shift(lag)\n",
    "    \n",
    "    # ROLLING STATISTICS - USING SAFE METHOD\n",
    "    print(\"Creating rolling features...\")\n",
    "    windows = [4, 8]   \n",
    "    \n",
    "    for window in windows:\n",
    "        # Retail rolling mean - using safe method\n",
    "        df[f'retail_roll_mean_{window}'] = safe_groupby_transform(\n",
    "            df, group_cols, target_col, lambda x: x.mean(), window\n",
    "        )\n",
    "        \n",
    "        # Retail rolling std\n",
    "        df[f'retail_roll_std_{window}'] = safe_groupby_transform(\n",
    "            df, group_cols, target_col, lambda x: x.std(), window\n",
    "        )\n",
    "    \n",
    "    # PRICE MOMENTUM \n",
    "    print(\"Creating momentum features...\")\n",
    "    df['retail_trend_4w'] = df['retail_lag_1'] - df['retail_lag_4']\n",
    "    \n",
    "    # Supply volume features\n",
    "    if 'Supply Volume' in df.columns:\n",
    "        print(\"Creating supply features...\")\n",
    "        df['supply_lag_1'] = df.groupby(group_cols)['Supply Volume'].shift(1)\n",
    "        \n",
    "        df['supply_roll_mean_4'] = safe_groupby_transform(\n",
    "            df, group_cols, 'Supply Volume', lambda x: x.mean(), 4\n",
    "        )\n",
    "    \n",
    "    # MARKET-LEVEL FEATURES (historical, no future data)\n",
    "    print(\"Creating market features...\")\n",
    "    df['market_retail_avg'] = df.groupby('Market')[target_col].transform(\n",
    "        lambda x: x.expanding(min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae07e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUTURE RETAIL PRICE PREDICTION WITH PROPER PRICE CLEANING\n",
      "============================================================\n",
      "BEFORE CLEANING:\n",
      "Retail price sample: ['-', '-', '-', '-', '-']\n",
      "Wholesale price sample: ['10.53/Kg', '17.78/Kg', '53.33/Kg', '50.00/Kg', '55.56/Kg']\n",
      "\n",
      "AFTER CLEANING:\n",
      "Retail price sample: [nan, nan, nan, nan, nan]\n",
      "Wholesale price sample: [10.53, 17.78, 53.33, 50.0, 55.56]\n",
      "\n",
      "DATA CLEANING SUMMARY:\n",
      "Initial rows: 310,304\n",
      "After removing missing retail prices: 256,614\n",
      "Rows removed: 53,690\n",
      "Date range: 2021-05-24 00:00:00 to 2025-09-17 00:00:00\n",
      "\n",
      "ðŸ’° PRICE STATISTICS:\n",
      "Retail - Mean: 170.71, Std: 392.57\n",
      "Retail - Min: 0.01, Max: 100000.00\n",
      "Wholesale - Mean: 121.80, Std: 236.72\n",
      "\n",
      "OUTLIER REMOVAL:\n",
      "Before filtering: 256,614 rows\n",
      "After filtering (1-5000 KES): 256,167 rows\n",
      "Rows removed: 447\n",
      "Creating lag features...\n",
      "Creating rolling features...\n",
      "Creating momentum features...\n",
      "Creating supply features...\n",
      "Creating market features...\n",
      "Adding categorical features...\n",
      "\n",
      "ðŸ“Š FINAL DATASET:\n",
      "Rows: 240,061\n",
      "Features: 40\n",
      "Date range: 2021-05-24 00:00:00 to 2025-09-17 00:00:00\n",
      "Remaining NaN values in features: 329156\n",
      "\n",
      "TRAINING MODEL...\n",
      "X shape: (240061, 40)\n",
      "y shape: (240061,)\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "\n",
      "MODEL PERFORMANCE:\n",
      "MAE: 27.39 KES\n",
      "RMSE: 113.84 KES\n",
      "Mean Retail Price: 172.86 KES\n",
      "MAE as % of mean: 15.8%\n",
      "\n",
      "TOP 10 FEATURE IMPORTANCE:\n",
      "           feature  importance\n",
      "retail_roll_mean_4    0.517917\n",
      "retail_roll_mean_8    0.268062\n",
      "      retail_lag_1    0.084249\n",
      " retail_roll_std_8    0.016325\n",
      " retail_roll_std_4    0.012624\n",
      " market_retail_avg    0.012075\n",
      "supply_roll_mean_4    0.010974\n",
      "   retail_trend_4w    0.009225\n",
      "      retail_lag_2    0.009127\n",
      "      supply_lag_1    0.008477\n",
      "\n",
      "SAMPLE PREDICTIONS (first 10):\n",
      "   Actual  Predicted  Error\n",
      "0  100.00     109.12  -9.12\n",
      "1   91.67     105.46 -13.79\n",
      "2   83.33     103.55 -20.22\n",
      "3   83.33      93.38 -10.05\n",
      "4   83.33      90.05  -6.72\n",
      "5   75.00      89.48 -14.48\n",
      "6   66.67      87.15 -20.48\n",
      "7   50.00      81.73 -31.73\n",
      "8   41.67      67.08 -25.41\n",
      "9   41.67      63.61 -21.94\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"FUTURE RETAIL PRICE PREDICTION WITH PROPER PRICE CLEANING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load and prepare data with robust price cleaning\n",
    "    df = prepare_data_with_proper_cleaning()\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No data available after cleaning!\")\n",
    "        return\n",
    "     \n",
    "    initial_count = len(df)\n",
    "    df = df[(df['Retail'] >= 1) & (df['Retail'] <= 5000)]   \n",
    "    filtered_count = len(df)\n",
    "    \n",
    "    print(f\"\\nOUTLIER REMOVAL:\")\n",
    "    print(f\"Before filtering: {initial_count:,} rows\")\n",
    "    print(f\"After filtering (1-5000 KES): {filtered_count:,} rows\")\n",
    "    print(f\"Rows removed: {initial_count - filtered_count:,}\")\n",
    "    \n",
    "    # Create future-safe features\n",
    "    df = create_future_safe_features(df)\n",
    "    \n",
    "    # Define feature columns  \n",
    "    feature_columns = [\n",
    "        # Temporal features\n",
    "        'year', 'month', 'week_of_year', 'day_of_year', 'quarter', 'day_of_week',\n",
    "        'is_long_rains', 'is_short_rains', 'is_planting_season', 'is_harvest_season',\n",
    "        \n",
    "        # Lagged retail prices\n",
    "        'retail_lag_1', 'retail_lag_2', 'retail_lag_3', 'retail_lag_4',\n",
    "        \n",
    "        # Rolling statistics\n",
    "        'retail_roll_mean_4', 'retail_roll_mean_8',\n",
    "        'retail_roll_std_4', 'retail_roll_std_8',\n",
    "        'retail_trend_4w',\n",
    "        \n",
    "        # Market features\n",
    "        'market_retail_avg'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    if 'Wholesale' in df.columns:\n",
    "        feature_columns.extend([\n",
    "            'wholesale_lag_1', 'wholesale_lag_2', 'wholesale_lag_4'\n",
    "        ])\n",
    "    \n",
    "  \n",
    "    if 'Supply Volume' in df.columns:\n",
    "        feature_columns.extend(['supply_lag_1', 'supply_roll_mean_4'])\n",
    "     \n",
    "    print(\"Adding categorical features...\")\n",
    "    for col in ['Commodity', 'Market', 'County']:\n",
    "        if col in df.columns:\n",
    "            # Get top categories\n",
    "            top_categories = df[col].value_counts().head(5).index  # Only top 5\n",
    "            for category in top_categories:\n",
    "                feature_name = f\"{col}_{category.replace(' ', '_').replace('/', '_')}\"\n",
    "                df[feature_name] = (df[col] == category).astype(int)\n",
    "                feature_columns.append(feature_name)\n",
    "    \n",
    "    # Remove rows with missing critical features\n",
    "    critical_features = ['retail_lag_1', 'retail_lag_2', 'month', 'year']\n",
    "    df_clean = df.dropna(subset=critical_features + ['Retail'])\n",
    "    \n",
    "    print(f\"\\nFINAL DATASET:\")\n",
    "    print(f\"Rows: {df_clean.shape[0]:,}\")\n",
    "    print(f\"Features: {len(feature_columns)}\")\n",
    "    print(f\"Date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n",
    "    \n",
    "    # Checking any remaining NaN values\n",
    "    print(f\"Remaining NaN values in features: {df_clean[feature_columns].isna().sum().sum()}\")\n",
    "    \n",
    "    # Fill any remaining NaN values with median\n",
    "    for col in feature_columns:\n",
    "        if df_clean[col].isna().any():\n",
    "            if np.issubdtype(df_clean[col].dtype, np.number):\n",
    "                df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "            else:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "    \n",
    "    # Prepare data for modeling\n",
    "    X = df_clean[feature_columns]\n",
    "    y = df_clean['Retail']\n",
    "    \n",
    "    print(f\"\\nTRAINING MODEL...\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # Use simpler validation for now\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=50,  \n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"\\nMODEL PERFORMANCE:\")\n",
    "    print(f\"MAE: {mae:.2f} KES\")\n",
    "    print(f\"RMSE: {rmse:.2f} KES\")\n",
    "    print(f\"Mean Retail Price: {y_train.mean():.2f} KES\")\n",
    "    print(f\"MAE as % of mean: {(mae / y_train.mean() * 100):.1f}%\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTOP 10 FEATURE IMPORTANCE:\")\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "    \n",
    "    # Show some actual vs predicted examples\n",
    "    print(f\"\\nSAMPLE PREDICTIONS (first 10):\")\n",
    "    results_sample = pd.DataFrame({\n",
    "        'Actual': y_test.values[:10],\n",
    "        'Predicted': y_pred[:10],\n",
    "        'Error': y_test.values[:10] - y_pred[:10]\n",
    "    })\n",
    "    print(results_sample.round(2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a448daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
